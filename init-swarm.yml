# set global variable once using the 'target self' trick

- name: Setup isolated docker hosts
  import_playbook: isolate-docker.yml

- name: Push sshnfs configuration before swarm is updated (in case new nodes are being added)
  import_playbook: push-sshnfs.yml



- hosts: swarmManagers:swarmWorkers
  vars_files:
    - vars/main.yml
  tasks:
    - set_fact:
        # this is a global variable
        managers_list: []
    - name: Ensure docker and python dependencies are installed
      package:
        name: 
          - docker.io
          - python3-requests
          - python3-docker
        state: present
    - name: Ensure internal nameserver is set as resolver for swarm nodes
      lineinfile:
        path: /etc/resolv.conf
        line: nameserver {{ item }}
        insertbefore: BOF
      loop: "{{ nameservers }}"

# scroll through managers and collect list of managers
- name: Fetch list of all available managers
  hosts: swarmManagers
  become: true
  tasks:
    - block:
      - name: Ensure jq is installed in manager node
        package:
          name: jq
          state: present
      - name: Check if there is at least one manager in the swarm
        shell: docker info -f {{ '"' + '{{json .Swarm.RemoteManagers }}' + '"' }} | jq '.[].Addr' | cut -d'"' -f 2
        register: manager_report
      - set_fact:
          managers_list: "{{ manager_report.stdout_lines }}"

# managers are aligned once so they all know (including swarmManager[0]) the starting situation in the cluster
- name: Align all managers on managers_list
  hosts: swarmManagers
  tasks:
    - set_fact:
        managers_list: "{{ (managers_list + hostvars[item]['managers_list']) | unique }}"
      loop: "{{ groups['swarmManagers'] }}"
    # - debug:
    #     msg: "{{ managers_list }}"

# init swarm in the first manager not that comes up, if managers_list is empty
- name: Bootstrap Swarm in manager 0
  hosts: swarmManagers[0]
  tasks:
    # - debug:
    #     msg: "{{ inventory_hostname }}"
    - name: Initialize swarm in first manager, and fetch access tokens
      block:
      - name: Initialize Swarm in original manager
        community.docker.docker_swarm:
          state: present
        register: manager_metadata_plain
        when: "'isolatedDockerHosts' not in group_names"
      - name: Initialize Swarm in original manager (isolated)
        community.docker.docker_swarm:
          state: present
          advertise_addr: ansible_facts.wg0.ipv4.address
        register: manager_metadata_isolated
        when: "'isolatedDockerHosts' in group_names"
      # - debug:
      #     msg: "{{ manager_metadata }}"   
      - set_fact:
          manager_metadata: "{{ manager_metadata_isolated if manager_metadata_isolated.stdout is defined else manager_metadata_plain }}"
      - name: Fetch original manager's address
        shell: docker info -f {{ '"' + '{{json .Swarm.RemoteManagers }}' + '"' }} | jq '.[].Addr' | cut -d'"' -f 2
        register: manager_report
      - name: Add original manager's address to managers_list
        set_fact:
          managers_list: "{{ managers_list + [manager_report.stdout_lines[0]]}}"
      when: 'managers_list | length == 0'


- name: Check swarm status (again if bootstrap was necessary) and set manager_token and worker_token
  hosts: swarmManagers[0]
  tasks:
    - name: Initialize Swarm in original manager
      community.docker.docker_swarm:
        state: present
      register: manager_metadata_plain
      when: "'isolatedDockerHosts' not in group_names"
    - name: Initialize Swarm in original manager (isolated)
      community.docker.docker_swarm:
        state: present
        advertise_addr: ansible_facts.wg0.ipv4.address
      register: manager_metadata_isolated
      when: "'isolatedDockerHosts' in group_names"
    - set_fact:
        manager_metadata: "{{ manager_metadata_isolated if manager_metadata_isolated.stdout is defined else manager_metadata_plain }}"
    - name: Fetch original manager's address
      shell: docker info -f {{ '"' + '{{json .Swarm.RemoteManagers }}' + '"' }} | jq '.[].Addr' | cut -d'"' -f 2
      register: manager_report
    - name: Set manager_token, worker_token and add original manager's address to managers_list
      set_fact:
        manager_token: "{{ manager_metadata.swarm_facts.JoinTokens.Manager }}"
        worker_token: "{{ manager_metadata.swarm_facts.JoinTokens.Worker }}"


- name: Align all swarm hosts' facts with manager 0
  hosts: swarmManagers:swarmWorkers
  tasks:
    - set_fact:
        managers_list: "{{ hostvars[groups['swarmManagers'][0]]['managers_list'] }}"
        manager_token: "{{ hostvars[groups['swarmManagers'][0]]['manager_token'] }}"
        worker_token: "{{ hostvars[groups['swarmManagers'][0]]['worker_token'] }}"
        # "{{ (managers_list + hostvars[item]['managers_list']) | unique }}"
        # manager_token: "{{ (manager_token + hostvars[item]['manager_token']) | unique }}"
        # worker_token: "{{ (worker_token + hostvars[item]['worker_token']) | unique }}"
      #loop: "{{ groups['swarmManagers'] + groups['swarmWorkers'] | unique }}"

- name: Ensure all swarm hosts join the swarm
  hosts: swarmManagers:swarmWorkers
  tasks:
    # - debug:
    #     msg: 
    #       - "{{ ('swarmManagers' in group_names) |ternary(manager_token, worker_token) }}"
    #       - "{{ managers_list }}"
    - name: Add node to swarm
      community.docker.docker_swarm:
        state: join
        join_token: "{{ ('swarmManagers' in group_names) |ternary(manager_token, worker_token) }}"
        remote_addrs: "{{ managers_list }}"
      when: "'isolatedDockerHosts' not in group_names"
    - name: Add node to swarm (isolated)
      community.docker.docker_swarm:
        state: join
        join_token: "{{ ('swarmManagers' in group_names) |ternary(manager_token, worker_token) }}"
        remote_addrs: "{{ managers_list }}"
        advertise_addr: ansible_facts.wg0.ipv4.address
      when: "'isolatedDockerHosts' in group_names"

- name: Deploy swarmpit to manager nodes
  hosts: swarmManagers
  vars:
    random_manager: "{{ groups['swarmManagers'] | random }}"
  tasks:
    - community.docker.docker_swarm_service:
        name: swarmpit
        image: swarmpit/install:1.9
        placement:
          constraints:
            - node.role == manager
        replicas: 1
        restart_config:
          condition: none
        env:
          INTERACTIVE: '0'
          APP_PORT: '888'
          ADMIN_USERNAME: 'swarmpit'
          ADMIN_PASSWORD: '{{ swarmpit_password }}'
        mounts:
          - source: /var/run/docker.sock
            target: /var/run/docker.sock
      when: 'inventory_hostname == random_manager'